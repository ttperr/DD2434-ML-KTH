{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Reparameterization of common distributions***\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AALnQO-y6HOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will work with Torch throughout this notebook."
      ],
      "metadata": {
        "id": "wRc3KUnVPHm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.distributions import Beta #, ...  import the distributions you need here\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "9hD0wA4YPFzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A helper function to visualize the generated samples:"
      ],
      "metadata": {
        "id": "HSQ2cI-_QeEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def compare_samples (samples_1, samples_2, bins=100, range=None):\n",
        "  fig = plt.figure()\n",
        "  if range is not None:\n",
        "    plt.hist(samples_1, bins=bins, range=range)\n",
        "    plt.hist(samples_2, bins=bins, range=range)\n",
        "  else:\n",
        "    plt.hist(samples_1, bins=bins)\n",
        "    plt.hist(samples_2, bins=bins)\n",
        "  plt.xlabel('value')\n",
        "  plt.ylabel('number of samples')\n",
        "  plt.legend(['direct','via reparameterization'])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "8U4TWTzs9KVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Q1. Exponential Distribution***\n",
        "Below write a function that generates N samples from $Exp (\\lambda)$."
      ],
      "metadata": {
        "id": "2UcchbfK_isG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_sampler(l, N):\n",
        "  # insert your code\n",
        "  return samples # should be N-by-1"
      ],
      "metadata": {
        "id": "K3Phd_jt_xcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, implement the reparameterization trick:"
      ],
      "metadata": {
        "id": "wX19swaIRzGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_reparametrize(l,N):\n",
        "  # this function should return N samples via reparametrization,\n",
        "  # insert your code\n",
        "  return samples"
      ],
      "metadata": {
        "id": "XTc92D_k_zvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate samples for $\\lambda = 1$ and compare:"
      ],
      "metadata": {
        "id": "fP_klfnoSMOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = 1    #lambda\n",
        "N = 1000\n",
        "direct_samples = exp_sampler(l, N)\n",
        "reparametrized_samples = exp_reparametrize(l, N)\n",
        "compare_samples(direct_samples, reparametrized_samples)"
      ],
      "metadata": {
        "id": "WQeU4IXoAWFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Q2. Categorical Distribution***\n",
        "Below write a function that generates N samples from Categorical (**a**), where **a** = $[a_0, a_1, a_2, a_3]$."
      ],
      "metadata": {
        "id": "9oSfkJfGAzNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_sampler(a, N):\n",
        "  # insert your code\n",
        "\n",
        "  return samples  # should be N-by-1"
      ],
      "metadata": {
        "id": "IsBBxMRgBLIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now write a function that generates samples from Categorical (**a**) via reparameterization:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_ZalUgMQTC68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint: approximate the Categorical distribution with the Gumbel-Softmax distribution\n",
        "def categorical_reparametrize(a, N, temp=0.1, eps=1e-20):  # temp and eps are hyperparameters for Gumbel-Softmax\n",
        "  # insert your code\n",
        "\n",
        "\n",
        "  return samples # make sure that your implementation allows the gradient to backpropagate\n"
      ],
      "metadata": {
        "id": "jxe9O-RIBSRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate samples when $a = [0.1,0.2,0.5,0.2]$ and visualize them:"
      ],
      "metadata": {
        "id": "afyIAchkVVnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([0.1,0.2,0.5,0.2])\n",
        "N = 1000\n",
        "direct_samples = categorical_sampler(a, N)\n",
        "reparametrized_samples = categorical_reparametrize(a, N, temp=0.1, eps=1e-20)\n",
        "compare_samples(direct_samples, reparametrized_samples)"
      ],
      "metadata": {
        "id": "xxvilsshB7yS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}