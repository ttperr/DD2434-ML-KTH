\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{fancyhdr} % Header
\usepackage{lastpage}
\usepackage[a4paper, total={7in, 9in}]{geometry}
\usepackage{float} % Floating position
\usepackage{hyperref} % Links
\usepackage{amsmath} % Math
\usepackage{amssymb} % Math
\usepackage{pdfpages} % Import pdf

\graphicspath{{images/}}

\newcommand{\authorFst}{Tristan Perrot}
\newcommand{\emailFst}{\href{mailto:tristanp@kth.se}{tristanp@kth.se}}
\newcommand{\authorSnd}{Ã‰tienne Riguet}
\newcommand{\emailSnd}{\href{mailto:riguet@kth.se}{riguet@kth.se}}

\pagestyle{fancy}
\fancyhf{} % clear all header and footer fields
\lhead{Assignment 2A \\ DD2434 - Machine Learning, Advanced Course}
\rhead{\authorFst \\ \authorSnd}
\cfoot{\thepage \  / \pageref{LastPage}}
\setlength{\headheight}{23pt}
\setlength{\footskip}{70pt}

\title{DD2434 - Machine Learning, Advanced Course \\ Assignment 2A}
\author{\authorFst \\ \emailFst \and \authorSnd \\ \emailSnd}
\date{December 2023}

\begin{document}

\maketitle

\begin{center}
    \includegraphics[scale=0.5]{KTH_logo_RGB_bla.png}
\end{center}

\thispagestyle{empty}

\newpage
\tableofcontents
\newpage

\section{Principal Component Analysis}

\subsection{Question 1}

Centering the data is a crucial step in Principal Component Analysis (PCA) because it removes the mean bias and makes the interpretation of principal components more straightforward. Indeed, if the data is not centered, the first principal component will be the direction of the mean of the data, and the second principal component will be the direction of the variance of the data. Therefore, the first principal component will not be the direction of the maximum variance of the data, and the second principal component will not be the direction of the second maximum variance of the data. In other words, the principal components will not be the directions of the maximum variance of the data.

\subsection{Question 2}

TODO

\subsection{Question 3}

The \it{variance} of the dataset $\mathcal{Y}$ is defined as $\text{Var}(\mathcal{Y}) = \sum_{y \in \mathcal{Y}} \left\lVert y - \overline{y} \right\rVert^2_2 = \sum_{y \in \mathcal{Y}} \left\lVert y \right\rVert^2_2$ here because the data is centered. Therefore we have:
\begin{equation}
    \begin{split}
        \text{Var}(\mathcal{Y}) &= \sum_{y \in \mathcal{Y}} \left\lVert y \right\rVert^2_2 \\
        &= \sum_{y \in \mathcal{Y}} y^T y \\
        &= \sum_{i = 1}^d (Y^T Y)_{i, i} \\
        &= \text{Tr}(Y^T Y) \\
        &= \text{Tr}(V \Sigma^T U^T U \Sigma V^T) \\
        &= \text{Tr}(V \Sigma^T \Sigma V^T) \\
        &= \text{Tr}(\Sigma^T \Sigma) \\
        \text{Var}(\mathcal{Y}) &= \sum_{i = 1}^d \sigma_i^2
    \end{split}
\end{equation}

\subsection{Question 4}

The \it{variance} of the projected dataset after PCA is $Var(\mathcal{X}) = \sum_{x \in \mathcal{X}} \left\lVert x \right\rVert^2_2$. Where $X = W^TY$ is a $k \times n$ matrix. Therefore we have:
\begin{equation}
    \begin{split}
        \text{Var}(\mathcal{X}) &= \sum_{x \in \mathcal{X}} \left\lVert x \right\rVert^2_2 \\
        &= \sum_{x \in \mathcal{X}} x^T x \\
        &= \sum_{i = 1}^k (X^T X)_{i, i} \\
        &= \text{Tr}(X X^T) \\
        &= \text{Tr}(W^T Y Y^T W) \\
        &= \text{Tr}(W^T U \Sigma \Sigma^T U^T W) \\
    \end{split}
\end{equation}

\newpage
\appendix
\section{Appendix}

\end{document}